{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8E7De68YVps",
   "metadata": {
    "id": "a8E7De68YVps"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
    "\n",
    "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34121147-1795-47bb-acae-ee6e1510dfbe",
   "metadata": {
    "id": "K6EHkj63XsUy"
   },
   "source": [
    "# Détails de l'étudiant\n",
    "### Nom(s)  : RAKOTOHARIMALALA \n",
    "### Prénom(s) : Ny Hasina Sedera\n",
    "### Classe : ESIIA4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
    "\n",
    "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape1",
   "metadata": {
    "id": "etape1"
   },
   "source": [
    "## Étape 1 : Introduction et Configuration de l'Environnement\n",
    "\n",
    "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
    "\n",
    "### Explication Pratique\n",
    "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "code-etape1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "code-etape1",
    "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importer les bibliothèques nécessaires\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Version de TensorFlow :', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question1",
   "metadata": {
    "id": "question1"
   },
   "source": [
    "### Question  1\n",
    "\n",
    "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f126f",
   "metadata": {},
   "source": [
    "Il est essentiel de vérifier la configuration de l'environnement avant de développer un modèle de deep learning pour : \n",
    "- **Eviter les incompatibilités** : Des écarts entre les versions des bibliothèques peuvent entraîner des erreurs d’exécution, des comportements inattendus ou une baisse de performance du modèle.\n",
    "- **Garantir la reproductibilité** : En précisant avec rigueur les versions utilisées, on s’assure d’obtenir des résultats cohérents, quel que soit l’environnement d’exécution.\n",
    "- **Optimiser l’utilisation du matériel** : Certaines versions de bibliothèques sont spécialement optimisées pour certaines architectures matérielles (CPU, GPU, TPU), améliorant ainsi la rapidité et l’efficacité du traitement.\n",
    "- **Simplifier la gestion des dépendances** : L’emploi d’environnements virtuels (comme conda ou venv) permet d’isoler les bibliothèques de chaque projet et d’éviter les conflits entre installations.\n",
    "- **Assurer la stabilité et simplifier la maintenance** : Un environnement bien structuré limite les bugs causés par des mises à jour non maîtrisées et simplifie la gestion du projet sur le long terme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape2",
   "metadata": {
    "id": "etape2"
   },
   "source": [
    "## Étape 2 : Chargement et Prétraitement des Données\n",
    "\n",
    "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
    "\n",
    "### Explication Pratique\n",
    "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape2",
   "metadata": {
    "id": "code-etape2"
   },
   "outputs": [],
   "source": [
    "# Charger le jeu de données CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
    "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question2",
   "metadata": {
    "id": "question2"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255ec30",
   "metadata": {},
   "source": [
    "### Normalisation des pixels et one-hot encoding des étiquettes  \n",
    "\n",
    "#### **1. Normalisation des pixels**  \n",
    "- **Stabilité** : Ramener les valeurs des pixels dans l’intervalle [0,1] réduit les écarts excessifs, évitant ainsi des gradients instables et la saturation des fonctions d’activation. Cela facilite un passage fluide des données dans le réseau, favorisant un apprentissage équilibré. \n",
    "- **Efficacité** :  Accélère l’entraînement en optimisant l’ajustement des poids et en stabilisant les algorithmes d’optimisation comme Adam ou SGD. De plus, cette homogénéisation des entrées améliore la généralisation du modèle.\n",
    "#### **2. One-hot encoding des étiquettes**  \n",
    "- **Stabilité** :  Convertir les étiquettes en vecteurs binaires empêche le modèle d’inférer une relation d’ordre entre les classes (par exemple, éviter que la classe 2 soit perçue comme plus grande que la classe 1). Cela garantit une meilleure interprétation des catégories.\n",
    "- **Efficacité** : Améliore la précision de l’apprentissage en rendant possible l’utilisation de fonctions de perte adaptées comme categorical_crossentropy. Cela permet également au réseau de calculer correctement les probabilités pour chaque classe et d’éviter des erreurs de classification dues à un encodage inapproprié des sorties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape3",
   "metadata": {
    "id": "etape3"
   },
   "source": [
    "## Étape 3 : Exploration et Visualisation des Données\n",
    "\n",
    "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
    "\n",
    "### Explication Pratique\n",
    "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape3",
   "metadata": {
    "id": "code-etape3"
   },
   "outputs": [],
   "source": [
    "# Afficher quelques images du jeu de données d'entraînement\n",
    "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
    "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question3",
   "metadata": {
    "id": "question3"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22478ae",
   "metadata": {},
   "source": [
    "### Impact d’une distribution inégale des classes et des images de mauvaise qualité sur la performance du modèle\n",
    "\n",
    "#### **1. Effets d’une distribution inégale des classes**  \n",
    "  - **Biais du modèle** : Si certaines classes sont sous-représentées, le modèle risque d’être biaisé en faveur des classes majoritaires et d’avoir du mal à bien généraliser sur les classes rares.\n",
    "  - **Mauvaise généralisation** :  Le modèle pourrait avoir un taux d’erreur plus élevé sur les classes minoritaires, car il n’a pas assez d’exemples pour apprendre leurs caractéristiques distinctives.\n",
    "  - **Métriques déséquilibrées** : Une forte présence d’une classe dominante peut fausser des indicateurs comme l’accuracy, rendant le modèle apparemment performant alors qu’il ne prédit correctement que les classes les plus fréquentes.\n",
    "\n",
    "#### **2. Effets des images de mauvaise qualité**  \n",
    "- **Difficulté d’apprentissage** : Des images floues, bruitées ou mal étiquetées peuvent perturber l’apprentissage du modèle en introduisant des erreurs dans les données.  \n",
    "- **Mauvaise convergence** :  Si trop d’images sont de mauvaise qualité, le modèle peut apprendre des caractéristiques non pertinentes, ce qui dégrade la performance globale.\n",
    "\n",
    "### Stratégies pour pallier ces problèmes\n",
    "\n",
    " #### **1. Pour équilibrer la distribution des classes**\n",
    " - **Rééchantillonnage des données** :\n",
    "   - Sur-échantillonner les classes sous-représentées (ajout d’exemples par duplication ou synthèse d’images via des techniques comme SMOTE).\n",
    "   - Sous-échantillonner les classes majoritaires pour réduire l’effet de dominance.\n",
    "\n",
    "- **Utiliser des métriques adaptées** : Privilégier des métriques comme le F1-score ou l’AUC-ROC au lieu de l’accuracy pour mieux évaluer les performances sur toutes les classes.\n",
    "- **Pondération des classes** : Attribuer un poids plus important aux classes rares lors de l’entraînement pour compenser leur faible représentation.\n",
    "\n",
    "   #### **2. Pour améliorer la qualité des images**\n",
    "   - **Nettoyage des données** : Identifier et supprimer les images mal étiquetées ou trop bruitées.\n",
    "   - **Techniques de prétraitement** : Appliquer des filtres pour améliorer la netteté et réduire le bruit dans les images.\n",
    "   - **Augmentation des données** : Utiliser des transformations (rotation, recadrage, ajustement des couleurs) pour enrichir le jeu de données et rendre le modèle plus robuste aux variations visuelles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape4",
   "metadata": {
    "id": "etape4"
   },
   "source": [
    "## Étape 4 : Construction du Modèle CNN\n",
    "\n",
    "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
    "\n",
    "### Explication Pratique\n",
    "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape4",
   "metadata": {
    "id": "code-etape4"
   },
   "outputs": [],
   "source": [
    "# Construire le modèle CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Bloc de convolution 2 : 64 filtres\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Bloc de convolution 3 : 64 filtres\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question4",
   "metadata": {
    "id": "question4"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcaae02",
   "metadata": {},
   "source": [
    "\n",
    "#### **Rôle des composants du CNN**  \n",
    "- **1-Couches de convolution**\n",
    "    - Détectent les caractéristiques locales (bords, textures, formes).\n",
    "    - Extraitent des informations de plus en plus complexes à chaque couche.\n",
    "- **2-Couches de Pooling** :\n",
    "    - Réduisent la taille des cartes de caractéristiques, limitant la charge computationnelle.\n",
    "    - Rendent le modèle plus robuste aux variations de position et de taille des objets.\n",
    "- **2-Couches de Dropout** :\n",
    "    - Prévenient le surapprentissage en désactivant aléatoirement certains neurones.\n",
    "    - Améliorent la généralisation du modèle sur de nouvelles images.\n",
    "  \n",
    "#### **Interaction entre les composants**  \n",
    "    - La convolution extrait les caractéristiques, le pooling les simplifie, et le dropout empêche la suradaptation.\n",
    "    - Ensemble, ces couches permettent au CNN d’analyser efficacement les images et de les classifier avec précision.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape5",
   "metadata": {
    "id": "etape5"
   },
   "source": [
    "## Étape 5 : Compilation et Entraînement du Modèle\n",
    "\n",
    "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
    "\n",
    "### Explication Pratique\n",
    "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape5",
   "metadata": {
    "id": "code-etape5"
   },
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question5",
   "metadata": {
    "id": "question5"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d60e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Effets d'un choix inadapté d'hyperparamètres**  \n",
    "- **Taux d'apprentissage** :\n",
    "    - Un taux trop élevé peut empêcher le modèle de converger correctement en provoquant des fluctuations importantes.\n",
    "    - Un taux trop faible ralentit l’apprentissage et peut bloquer le modèle dans un minimum sous-optimal. \n",
    "- **Taille du batch** :\n",
    "    - Une taille trop petite rend l'entraînement plus instable en introduisant du bruit.\n",
    "    - Une taille trop grande peut limiter la capacité du modèle à généraliser et augmenter l'utilisation de mémoire.\n",
    "\n",
    "#### **Importance d'un optimiseur bien configuré**  \n",
    "Un optimiseur comme Adam ou SGD, bien paramétré, ajuste efficacement les poids du modèle, favorisant une convergence stable et rapide tout en évitant les erreurs d’optimisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape6",
   "metadata": {
    "id": "etape6"
   },
   "source": [
    "## Étape 6 : Évaluation du Modèle\n",
    "\n",
    "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
    "\n",
    "### Explication Pratique\n",
    "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape6",
   "metadata": {
    "id": "code-etape6"
   },
   "outputs": [],
   "source": [
    "# Évaluer le modèle sur le jeu de test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Précision sur le jeu de test :', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question6",
   "metadata": {
    "id": "question6"
   },
   "source": [
    "### Question  6\n",
    "\n",
    "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48934736",
   "metadata": {},
   "source": [
    "#### **Perte et précision sur le jeu de test**  \n",
    "- **Perte** : Indique à quel point les prédictions du modèle s’écartent des valeurs réelles. Une perte élevée suggère un mauvais ajustement aux données.\n",
    "- **Précision** : Mesure la proportion de prédictions correctes. Une précision élevée signifie que le modèle classe bien les images.\n",
    "#### **Ajustements à envisager en cas d'écart significatif**  \n",
    "- **Si surapprentissage (overfitting)** → Bonne performance en entraînement mais mauvaise en test : \n",
    "  - Ajouter du dropout ou d'autres techniques de régularisation.\n",
    "  - Utiliser de l’augmentation de données pour améliorer la généralisation.\n",
    "  - Réduire la complexité du modèle (moins de couches ou de neurones).\n",
    "- **Si sous-apprentissage (underfitting)** → Mauvaise performance sur les deux ensembles :\n",
    "  - Entraîner plus longtemps ou ajuster le taux d’apprentissage.\n",
    "  -Essayer un modèle plus complexe avec plus de couches.\n",
    "  -Ajouter plus de données d’entraînement si possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape7",
   "metadata": {
    "id": "etape7"
   },
   "source": [
    "## Étape 7 : Prédictions et Visualisation des Résultats\n",
    "\n",
    "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
    "\n",
    "### Explication Pratique\n",
    "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape7",
   "metadata": {
    "id": "code-etape7"
   },
   "outputs": [],
   "source": [
    "# Faire des prédictions sur le jeu de test\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
    "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    etiquette_predite = np.argmax(predictions_array)\n",
    "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
    "\n",
    "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
    "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
    "\n",
    "# Afficher quelques images de test avec leurs prédictions\n",
    "nb_lignes = 5\n",
    "nb_colonnes = 3\n",
    "nb_images = nb_lignes * nb_colonnes\n",
    "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
    "for i in range(nb_images):\n",
    "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
    "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question7",
   "metadata": {
    "id": "question7"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9357c15",
   "metadata": {},
   "source": [
    "\n",
    "#### **Stratégies pour améliorer la robustesse et la précision du modèle**  \n",
    "- **Augmentation des données** : Générer des variations (rotation, zoom, bruit) pour améliorer la capacité du modèle à généraliser et éviter qu’il se focalise sur des caractéristiques spécifiques. \n",
    "- **Optimisation de l'architecture** :Ajouter des couches convolutionnelles, ajuster la taille des filtres ou tester différentes architectures (ResNet, VGG, EfficientNet) pour extraire des caractéristiques plus pertinentes.\n",
    "- **Ajustement des hyperparamètres** : Optimiser le taux d’apprentissage, la taille du batch ou la fonction d’activation pour améliorer la convergence et la stabilité de l’entraînement.\n",
    "- **Pondération des classes** : En cas de déséquilibre entre les classes, ajuster leur poids dans la fonction de perte pour éviter que le modèle ne favorise les classes majoritaires et garantir un apprentissage plus équilibré.\n",
    "\n",
    "Ces stratégies permettent de rendre le modèle plus robuste face aux variations des données et d'améliorer sa précision sur de nouveaux exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape8",
   "metadata": {
    "id": "etape8"
   },
   "source": [
    "## Étape 8 : Conclusion et Travaux Futurs\n",
    "\n",
    "Dans ce notebook, nous avons :\n",
    "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
    "- Chargé et prétraité le jeu de données CIFAR-10\n",
    "- Exploré et visualisé les données\n",
    "- Construit, compilé et entraîné un modèle CNN\n",
    "- Évalué le modèle et visualisé ses prédictions\n",
    "\n",
    "### Explication Pratique\n",
    "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
