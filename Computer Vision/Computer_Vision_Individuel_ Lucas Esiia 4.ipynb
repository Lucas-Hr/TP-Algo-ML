{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8E7De68YVps",
   "metadata": {
    "id": "a8E7De68YVps"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
    "\n",
    "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K6EHkj63XsUy",
   "metadata": {
    "id": "K6EHkj63XsUy"
   },
   "source": [
    "# Détails de l'étudiant\n",
    "### Nom(s)  : Randriamiarisoa\n",
    "### Prénom(s) : Henintsoa Lucas\n",
    "### Classe : Esiia4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
    "\n",
    "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape1",
   "metadata": {
    "id": "etape1"
   },
   "source": [
    "## Étape 1 : Introduction et Configuration de l'Environnement\n",
    "\n",
    "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
    "\n",
    "### Explication Pratique\n",
    "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "code-etape1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "code-etape1",
    "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de TensorFlow : 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Version de TensorFlow :', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question1",
   "metadata": {
    "id": "question1"
   },
   "source": [
    "### Question  1\n",
    "\n",
    "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f1ca1-4274-4c3c-a456-4cc98cbe5f76",
   "metadata": {},
   "source": [
    "### Reponse 1\n",
    "Vérifier la configuration de l’environnement avant de développer un modèle de deep learning est crucial pour garantir la compatibilité des versions, la reproductibilité des résultats et l’optimisation des performances. Cela évite les erreurs dues aux conflits de dépendances et assure un entraînement stable et efficace du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape2",
   "metadata": {
    "id": "etape2"
   },
   "source": [
    "## Étape 2 : Chargement et Prétraitement des Données\n",
    "\n",
    "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
    "\n",
    "### Explication Pratique\n",
    "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape2",
   "metadata": {
    "id": "code-etape2"
   },
   "outputs": [],
   "source": [
    "# Charger le jeu de données CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
    "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question2",
   "metadata": {
    "id": "question2"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b7a09-0468-4a17-b63f-b747459a731d",
   "metadata": {},
   "source": [
    "### Reponse 2\n",
    "La normalisation des pixels accélère la convergence du modèle en réduisant la variance des entrées, évitant ainsi des mises à jour instables des poids lors de l'entraînement. Le one-hot encoding des étiquettes permet au modèle de mieux distinguer les classes en évitant une hiérarchie implicite entre les catégories, ce qui améliore la stabilité de la fonction de perte et optimise l’apprentissage, comme observé dans les travaux sur la classification multi-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape3",
   "metadata": {
    "id": "etape3"
   },
   "source": [
    "## Étape 3 : Exploration et Visualisation des Données\n",
    "\n",
    "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
    "\n",
    "### Explication Pratique\n",
    "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape3",
   "metadata": {
    "id": "code-etape3"
   },
   "outputs": [],
   "source": [
    "# Afficher quelques images du jeu de données d'entraînement\n",
    "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
    "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question3",
   "metadata": {
    "id": "question3"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071a92b-ae88-4085-9c33-70b263ddad29",
   "metadata": {},
   "source": [
    "### Reponse 3\n",
    "Une distribution inégale des classes peut biaiser le modèle, le poussant à mieux reconnaître les classes majoritaires et à ignorer les classes minoritaires, comme démontré dans les recherches sur l'apprentissage supervisé. De plus, des images de mauvaise qualité (floues, bruitées) peuvent ralentir l’apprentissage et réduire la précision du modèle. Pour pallier ces problèmes, on peut équilibrer les classes par sur-échantillonnage ou pondération de la perte, et améliorer la qualité des images via des prétraitements comme le filtrage et l’augmentation de contraste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape4",
   "metadata": {
    "id": "etape4"
   },
   "source": [
    "## Étape 4 : Construction du Modèle CNN\n",
    "\n",
    "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
    "\n",
    "### Explication Pratique\n",
    "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape4",
   "metadata": {
    "id": "code-etape4"
   },
   "outputs": [],
   "source": [
    "# Construire le modèle CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Bloc de convolution 2 : 64 filtres\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Bloc de convolution 3 : 64 filtres\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question4",
   "metadata": {
    "id": "question4"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e18bb-6daa-4719-b663-14bed929d6d1",
   "metadata": {},
   "source": [
    "### Reponse 4\n",
    "1. Couches de Convolution (Conv2D)\n",
    "\n",
    "Ces couches sont responsables de l'extraction des caractéristiques des images d'entrée. Elles appliquent des filtres (ou \"kernels\") pour détecter différents motifs comme les bords, les textures ou des structures plus complexes.\n",
    "\n",
    "    Première couche de convolution (Conv2D avec 32 filtres, 3x3)\n",
    "\n",
    "        Applique 32 filtres de taille 3x3 sur l’image d’entrée.\n",
    "\n",
    "        Utilise la fonction d’activation ReLU pour introduire de la non-linéarité et éviter la saturation des gradients.\n",
    "\n",
    "        Produit une sortie de taille (30, 30, 32), car l’image d’entrée était de (32, 32, 3), et que les bords sont réduits par la convolution.\n",
    "\n",
    "    Deuxième couche de convolution (Conv2D avec 64 filtres, 3x3)\n",
    "\n",
    "        Applique 64 filtres 3x3 sur la sortie de la couche précédente.\n",
    "\n",
    "        Continue l’extraction de caractéristiques plus complexes.\n",
    "\n",
    "    Troisième couche de convolution (Conv2D avec 64 filtres, 3x3)\n",
    "\n",
    "        Extrait encore plus d’informations détaillées.\n",
    "\n",
    "        Plus on avance dans les couches, plus les filtres capturent des caractéristiques abstraites.\n",
    "\n",
    "2. Couches de Pooling (MaxPooling2D)\n",
    "\n",
    "Ces couches réduisent la taille des caractéristiques extraites tout en conservant les informations les plus importantes.\n",
    "\n",
    "    Pooling après la première convolution (MaxPooling2D, 2x2)\n",
    "\n",
    "        Réduit la dimension (30,30,32) en (15,15,32).\n",
    "\n",
    "        Permet de diminuer le nombre de paramètres et d’éviter le sur-apprentissage.\n",
    "\n",
    "    Pooling après la deuxième convolution (MaxPooling2D, 2x2)\n",
    "\n",
    "        Réduit encore la taille en (6,6,64).\n",
    "\n",
    "        Rend le modèle plus efficace en éliminant les détails redondants.\n",
    "\n",
    "3. Couche d'Aplatissement (Flatten)\n",
    "\n",
    "Cette couche transforme la sortie 3D des couches précédentes en un vecteur 1D.\n",
    "\n",
    "    Passage de (4, 4, 64) à (1024,).\n",
    "\n",
    "    Permet de connecter ces données à des couches entièrement connectées pour la classification.\n",
    "\n",
    "4. Couches Denses (Dense)\n",
    "\n",
    "Ces couches sont responsables de la prise de décision basée sur les caractéristiques extraites.\n",
    "\n",
    "    Première couche dense (Dense avec 64 neurones, ReLU)\n",
    "\n",
    "        Effectue un traitement plus complexe sur les caractéristiques extraites.\n",
    "\n",
    "        Utilise ReLU pour améliorer l’apprentissage.\n",
    "\n",
    "    Couche de sortie (Dense avec 10 neurones, Softmax)\n",
    "\n",
    "        Chaque neurone correspond à une classe (dans le cas d’un dataset à 10 classes).\n",
    "\n",
    "        Softmax convertit les valeurs en probabilités pour la classification finale.\n",
    "\n",
    "5. Couche de Dropout\n",
    "\n",
    "Cette couche empêche le sur-apprentissage en désactivant aléatoirement certains neurones pendant l'entraînement.\n",
    "\n",
    "    Ici, Dropout(0.5) désactive 50% des neurones de la couche précédente pour rendre le modèle plus robuste.\n",
    "\n",
    "Interaction des composants\n",
    "\n",
    "    Convolution → Détecte les motifs et caractéristiques locales.\n",
    "\n",
    "    Pooling → Réduit la taille des images tout en conservant l’essentiel.\n",
    "\n",
    "    Aplatissement → Transforme les caractéristiques en vecteur exploitable.\n",
    "\n",
    "    Couches Denses → Effectuent la classification finale.\n",
    "\n",
    "    Dropout → Empêche le modèle de mémoriser trop précisément les données d’entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape5",
   "metadata": {
    "id": "etape5"
   },
   "source": [
    "## Étape 5 : Compilation et Entraînement du Modèle\n",
    "\n",
    "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
    "\n",
    "### Explication Pratique\n",
    "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape5",
   "metadata": {
    "id": "code-etape5"
   },
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question5",
   "metadata": {
    "id": "question5"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8e3cf-fb8e-46ac-a5da-ed33052e1bc7",
   "metadata": {},
   "source": [
    "### Reponse 5\n",
    "Un choix inadapté des hyperparamètres peut gravement affecter l'entraînement d'un réseau de neurones. Un taux d'apprentissage trop élevé peut empêcher la convergence ou provoquer des oscillations instables, tandis qu'un taux trop faible ralentit l'entraînement et risque d'entraîner un minimum local sous-optimal. Une taille de batch trop grande peut réduire la généralisation en lissant trop les mises à jour des gradients, tandis qu'une taille trop petite introduit du bruit, rendant la convergence plus erratique. Un optimiseur bien configuré (comme Adam ou RMSprop) assure une mise à jour efficace des poids en ajustant dynamiquement les taux d'apprentissage et en accélérant la descente vers un minimum optimal, favorisant ainsi une convergence plus rapide et plus stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape6",
   "metadata": {
    "id": "etape6"
   },
   "source": [
    "## Étape 6 : Évaluation du Modèle\n",
    "\n",
    "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
    "\n",
    "### Explication Pratique\n",
    "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape6",
   "metadata": {
    "id": "code-etape6"
   },
   "outputs": [],
   "source": [
    "# Évaluer le modèle sur le jeu de test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Précision sur le jeu de test :', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question6",
   "metadata": {
    "id": "question6"
   },
   "source": [
    "### Question  6\n",
    "\n",
    "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919aad11-d856-4ce3-a1d4-f2475e93f8d7",
   "metadata": {},
   "source": [
    "### Response 6 \n",
    "Perte : 0.9552\n",
    "Precision : 0.6640\n",
    "Régularisation : Si l'écart entre l'entraînement et le test est important (overfitting), appliquez la régularisation L1/L2 ou utilisez Dropout pour réduire la complexité du modèle.\n",
    "\n",
    "Plus de données : L'augmentation de la quantité et de la diversité des données peut aider à améliorer la généralisation du modèle.\n",
    "\n",
    "Ajustement du modèle : Réduire la complexité du modèle (moins de couches ou de neurones) peut éviter le surajustement aux données d'entraînement.\n",
    "\n",
    "Optimisation du taux d’apprentissage : Un taux d'apprentissage mal réglé peut nuire à la convergence, il faut donc l'ajuster avec des techniques comme le scheduler ou l'annealing.\n",
    "\n",
    "Amélioration des features : Effectuer un meilleur prétraitement des données et extraire des features plus pertinentes peut améliorer la performance du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape7",
   "metadata": {
    "id": "etape7"
   },
   "source": [
    "## Étape 7 : Prédictions et Visualisation des Résultats\n",
    "\n",
    "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
    "\n",
    "### Explication Pratique\n",
    "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-etape7",
   "metadata": {
    "id": "code-etape7"
   },
   "outputs": [],
   "source": [
    "# Faire des prédictions sur le jeu de test\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
    "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    etiquette_predite = np.argmax(predictions_array)\n",
    "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
    "\n",
    "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
    "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
    "\n",
    "# Afficher quelques images de test avec leurs prédictions\n",
    "nb_lignes = 5\n",
    "nb_colonnes = 3\n",
    "nb_images = nb_lignes * nb_colonnes\n",
    "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
    "for i in range(nb_images):\n",
    "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
    "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "question7",
   "metadata": {
    "id": "question7"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
    "\n",
    "_Répondez dans une nouvelle cellule Markdown._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73747e78-28f4-477e-89d2-a7d43ab250fc",
   "metadata": {},
   "source": [
    "### Reponse 7\n",
    "1. Augmentation de Données\n",
    "\n",
    "    Si le modèle souffre de surajustement (overfitting), augmenter la diversité des données en appliquant des transformations (rotation, translation, mise à l'échelle, inversion, etc.) peut améliorer la généralisation.\n",
    "\n",
    "    En utilisant ImageDataGenerator de TensorFlow/Keras (ou d'autres techniques en fonction du framework utilisé), on peut générer des variations des images existantes.\n",
    "\n",
    "2. Raffinement de l’Architecture du Modèle\n",
    "\n",
    "    Ajouter des couches de régularisation comme Dropout pour éviter le surajustement.\n",
    "\n",
    "    Expérimenter avec différentes architectures, comme des CNN plus profonds ou des modèles pré-entraînés via le transfert d’apprentissage (ex. MobileNet, ResNet, VGG).\n",
    "\n",
    "    Tester différentes fonctions d’activation (ReLU, LeakyReLU, etc.).\n",
    "\n",
    "3. Ajustement des Hyperparamètres\n",
    "\n",
    "    Optimiser les hyperparamètres tels que :\n",
    "\n",
    "        Le taux d’apprentissage (learning rate), en utilisant une recherche par grille (GridSearchCV) ou une recherche aléatoire (RandomSearch).\n",
    "\n",
    "        La taille des mini-batchs et le nombre d’époques.\n",
    "\n",
    "        L’optimiseur (Adam, RMSprop, SGD, etc.).\n",
    "\n",
    "4. Amélioration des Données d’Entraînement\n",
    "\n",
    "    Vérifier si les données sont bien équilibrées entre les classes. En cas de déséquilibre, envisager du rééchantillonnage ou de la pondération des classes.\n",
    "\n",
    "    Nettoyer les données pour supprimer les erreurs ou les annotations incorrectes.\n",
    "\n",
    "5. Validation Croisée et Test avec des Données Non-Vues\n",
    "\n",
    "    Utiliser une validation croisée k-fold pour évaluer la performance sur plusieurs ensembles de test.\n",
    "\n",
    "    Tester sur des données réelles ou non vues pour vérifier la robustesse du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etape8",
   "metadata": {
    "id": "etape8"
   },
   "source": [
    "## Étape 8 : Conclusion et Travaux Futurs\n",
    "\n",
    "Dans ce notebook, nous avons :\n",
    "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
    "- Chargé et prétraité le jeu de données CIFAR-10\n",
    "- Exploré et visualisé les données\n",
    "- Construit, compilé et entraîné un modèle CNN\n",
    "- Évalué le modèle et visualisé ses prédictions\n",
    "\n",
    "### Explication Pratique\n",
    "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
